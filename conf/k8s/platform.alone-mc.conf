# k8s ingress metrics
# [[inputs.prometheus]]
#     interval = "1m"
#     urls = $K8S_INGRESS_URLS

# middleware
[[inputs.elasticsearch]]
    servers = "${ELASTICSEARCH_SERVERS}"
    http_timeout = "8s"
    local = "${ELASTICSEARCH_GATHER_LOCAL}"
    cluster_health = true
    cluster_health_level = "cluster"
    cluster_stats = false
    node_stats = ["indices", "transport", "http", "jvm", "fs", "os", "process"]
    [inputs.elasticsearch.tags]
      addon_id = "elasticsearch"
      addon_type = "elasticsearch"

# [[inputs.redis]]
#     servers = $REDIS_SERVERS

[[inputs.zookeeper]]
    servers = $ZOOKEEPER_SERVERS
    [inputs.zookeeper.tags]
      addon_id = "zookeeper"
      addon_type = "zookeeper"

# mysql
[[inputs.mysql]]
    servers = $MYSQL_SERVERS
    metric_version = 2
    perf_events_statements_digest_text_limit  = 120
    perf_events_statements_limit              = 250
    perf_events_statements_time_limit         = 86400
    table_schema_databases                    = []
    gather_table_schema                       = false
    gather_process_list                       = false
    gather_user_statistics                    = false
    gather_info_schema_auto_inc               = false
    gather_innodb_metrics                     = false
    gather_slave_status                       = false
    gather_binary_logs                        = false
    gather_table_io_waits                     = false
    gather_table_lock_waits                   = false
    gather_index_io_waits                     = false
    gather_event_waits                        = false
    gather_file_events_stats                  = false
    gather_perf_events_statements             = false
   # interval_slow                            = "30m"
    fieldpass = [ 
		"threads_connected",
		"queries", "questions", "slow_queries", 
		"com_commit",  "com_rollback", 
		"com_select", "com_insert", "com_update", "com_delete", 
		"innodb_data_read", "innodb_data_reads", "innodb_data_written", "innodb_data_writes",
		"bytes_sent", "bytes_received",
		"innodb_rows_deleted", "innodb_rows_inserted", "innodb_rows_read", "innodb_rows_updated", "uptime", 
        "open_tables", "threads_running","table_locks_waited"]
    [inputs.mysql.tags]
      addon_id = "mysql"
      addon_type = "mysql"

[[inputs.mysql_size_summary]]
    servers = $MYSQL_SERVERS
    per_database  = false
    [inputs.mysql_size_summary.tags]
      addon_id = "mysql"
      addon_type = "mysql"

[[inputs.cassandra_jolokia_wraper]]
  domain = "$CASSANDRA_EXPORTER_JMX_ADDR"
  port = $CASSANDRA_JOLOKIA_PORT
  name_prefix = "addon_java_"
  response_timeout = "15s"
  [inputs.cassandra_jolokia_wraper.tags]
    addon_id = "cassandra"
    addon_type = "cassandra"

  [[inputs.cassandra_jolokia_wraper.metrics]]
    name  = "Memory"
    mbean = "java.lang:type=Memory"
  [[inputs.cassandra_jolokia_wraper.metric]]
    name  = "GarbageCollector"
    mbean = "java.lang:name=*,type=GarbageCollector"
    tag_keys = ["name"]
    paths = ["CollectionCount", "CollectionTime", "Name", "Valid"]

[[inputs.cassandra_jolokia_wraper]]
  domain = "$CASSANDRA_EXPORTER_JMX_ADDR"
  port = $CASSANDRA_JOLOKIA_PORT
  name_prefix = "cassandra_"
  [inputs.cassandra_jolokia_wraper.tags]
    addon_id = "cassandra"
    addon_type = "cassandra"

  [[inputs.cassandra_jolokia_wraper.metric]]
    name  = "Client"
    mbean = "org.apache.cassandra.metrics:name=connectedNativeClients,type=Client"
    tag_keys = ["name"]
  [[inputs.cassandra_jolokia_wraper.metric]]
    name  = "ClientRequest"
    mbean = "org.apache.cassandra.metrics:name=Latency,scope=Read,type=ClientRequest"
    tag_keys = ["name", "scope"]
  [[inputs.cassandra_jolokia_wraper.metric]]
    name  = "ClientRequest"
    mbean = "org.apache.cassandra.metrics:name=Latency,scope=Write,type=ClientRequest"
    tag_keys = ["name", "scope"]
  [[inputs.cassandra_jolokia_wraper.metric]]
    name  = "ClientRequest"
    mbean = "org.apache.cassandra.metrics:name=Latency,scope=CASRead,type=ClientRequest"
    tag_keys = ["name", "scope"]
  [[inputs.cassandra_jolokia_wraper.metric]]
    name  = "ClientRequest"
    mbean = "org.apache.cassandra.metrics:name=Latency,scope=CASWrite,type=ClientRequest"
    tag_keys = ["name", "scope"]
  [[inputs.cassandra_jolokia_wraper.metric]]
    name  = "ClientRequest"
    mbean = "org.apache.cassandra.metrics:name=Latency,scope=RangeSlice,type=ClientRequest"
    tag_keys = ["name", "scope"]


[[inputs.jolokia2_agent]]
  urls = $KAFKA_JOLOKIA_URLS
  name_prefix = "addon_java_"
  [inputs.jolokia2_agent.tags]
    addon_id = "kafka"
    addon_type = "kafka"

  [[inputs.jolokia2_agent.metrics]]
    name  = "Memory"
    mbean = "java.lang:type=Memory"
  [[inputs.jolokia2_agent.metric]]
    name  = "GarbageCollector"
    mbean = "java.lang:name=*,type=GarbageCollector"
    tag_keys = ["name"]
    paths = ["CollectionCount", "CollectionTime", "Name", "Valid"]

[[inputs.jolokia2_agent]]
  urls = $KAFKA_JOLOKIA_URLS
  name_prefix = "kafka_"
  [inputs.jolokia2_agent.tags]
    addon_id = "kafka"
    addon_type = "kafka"

  [[inputs.jolokia2_agent.metric]]
    name         = "controller"
    mbean        = "kafka.controller:name=*,type=*"
    field_prefix = "$1."
  [[inputs.jolokia2_agent.metric]]
    name         = "replica_manager"
    mbean        = "kafka.server:name=*,type=ReplicaManager"
    field_prefix = "$1."
  [[inputs.jolokia2_agent.metric]]
    name         = "purgatory"
    mbean        = "kafka.server:delayedOperation=*,name=*,type=DelayedOperationPurgatory"
    field_prefix = "$1."
    field_name   = "$2"
  [[inputs.jolokia2_agent.metric]]
    name     = "client"
    mbean    = "kafka.server:client-id=*,type=*"
    tag_keys = ["client-id", "type"]
  [[inputs.jolokia2_agent.metric]]
    name         = "request"
    mbean        = "kafka.network:name=*,request=*,type=RequestMetrics"
    field_prefix = "$1."
    tag_keys     = ["request"]
  [[inputs.jolokia2_agent.metric]]
    name         = "topics"
    mbean        = "kafka.server:name=*,type=BrokerTopicMetrics"
    field_prefix = "$1."
  [[inputs.jolokia2_agent.metric]]
    name         = "topic"
    mbean        = "kafka.server:name=*,topic=*,type=BrokerTopicMetrics"
    field_prefix = "$1."
    tag_keys     = ["topic"]
  [[inputs.jolokia2_agent.metric]]
    name       = "partition"
    mbean      = "kafka.log:name=*,partition=*,topic=*,type=Log"
    field_name = "$1"
    tag_keys   = ["topic", "partition"]
  [[inputs.jolokia2_agent.metric]]
    name       = "partition"
    mbean      = "kafka.cluster:name=UnderReplicated,partition=*,topic=*,type=Partition"
    field_name = "UnderReplicatedPartitions"
    tag_keys   = ["topic", "partition"]

[[processors.point_space_to_underline]]
    namepass = ["addon_java_*", "cassandra_*", "kafka_*"]

[[inputs.kafka_monitor]]
    interval = "1m"
    servers = "$BOOTSTRAP_SERVERS"
    [inputs.kafka_monitor.tags]
        addon_id = "kafka"
        addon_type = "kafka"

[[inputs.prometheus]]
  urls = "${ETCD_URLS}"
  metric_name = "etcd"
  metric_version = 2
  tls_ca = "/netdata/dice-ops/dice-config/certificates/etcd-ca.pem"
  tls_cert = "/netdata/dice-ops/dice-config/certificates/etcd-client.pem"
  tls_key = "/netdata/dice-ops/dice-config/certificates/etcd-client-key.pem"
  insecure_skip_verify = true
  [inputs.prometheus.tags]
    addon_id = "etcd"
    addon_type = "etcd"
    edge_cluster = "true"

[[inputs.kube_inventory]]
  interval = "1m"
  namespace = "kube-system"
  url = "$MASTER_VIP_URL"
  # nodes, persistentvolumeclaims, persistentvolumes with all namespace
  resource_include = [ "nodes", "daemonsets", "statefulsets", "deployments", "persistentvolumes", "persistentvolumeclaims"]
  bearer_token = "/run/secrets/kubernetes.io/serviceaccount/token"
  tls_ca = "/run/secrets/kubernetes.io/serviceaccount/ca.crt"

[[inputs.kube_inventory]]
  interval = "1m"
  namespace = "default"
  url = "$MASTER_VIP_URL"
  resource_include = [ "daemonsets", "statefulsets", "deployments" ]
  bearer_token = "/run/secrets/kubernetes.io/serviceaccount/token"
  tls_ca = "/run/secrets/kubernetes.io/serviceaccount/ca.crt"

# watch event
[[inputs.kube_inventory]]
  url = "$MASTER_VIP_URL"
  bearer_token = "/run/secrets/kubernetes.io/serviceaccount/token"
  tls_ca = "/run/secrets/kubernetes.io/serviceaccount/ca.crt"
  # enable event watch, will disable all other resource collect
  [inputs.kube_inventory.event_watch]
    enable = true

#  coredns
[[inputs.prometheus]]
  interval = "1m"
  urls = ["http://$CLUSTER_DNS:9153"]
  metric_name = "coredns"
  metric_version = 2
  fieldpass = ["coredns_*"]
  [inputs.prometheus.tags]
    edge_cluster = "true"

# k8s apiserver
[[inputs.prometheus]]
  interval = "5m"
  urls = ["$MASTER_VIP_URL"]
  metric_name = "kubernetes_apiserver"
  metric_version = 2
  fieldpass = [
    "apiserver_request_duration_seconds",
    "apiserver_request_total",
    "workqueue_depth",
    "workqueue_adds_total",
    "workqueue_queue_duration_seconds",
    "go_goroutines"
  ]

# ingress
#[[inputs.prometheus]]
#  interval = "5m"
#  metric_name = "kubernetes_ingress"
#  metric_version = 2
#  fieldpass = [
#    "nginx_ingress_controller_requests",
#    "nginx_ingress_controller_ingress_upstream_latency_seconds*",
#  ]
#  bearer_token = "${K8S_BEARER_TOKEN:/run/secrets/kubernetes.io/serviceaccount/token}"
#  tls_ca = "${K8S_TLS_CA:/run/secrets/kubernetes.io/serviceaccount/ca.crt}"
#  # select pod address by label
#  [inputs.prometheus.kubernetes_selector]
#    enable = true
#    port = "10254"
#    namespace = "kube-system"
#  [inputs.prometheus.kubernetes_selector.label]
#    "app.kubernetes.io/name" = "ingress-nginx"

# kube controller
#[[inputs.prometheus]]
#  interval = "1m"
#  metric_name = "kubernetes_controller"
#  metric_version = 2
#  fieldpass = [
#    "workqueue_queue_duration_seconds*",
#    "workqueue_adds_total",
#    "workqueue_depth",
#    "rest_client_request_latency_seconds",
#    "rest_client_requests_total"
#  ]
#  bearer_token = "${K8S_BEARER_TOKEN:/run/secrets/kubernetes.io/serviceaccount/token}"
#  tls_ca = "${K8S_TLS_CA:/run/secrets/kubernetes.io/serviceaccount/ca.crt}"
#  # select pod address by label
#  [inputs.prometheus.kubernetes_selector]
#    enable = true
#    port = "10252"
#    namespace = "kube-system"
#  [inputs.prometheus.kubernetes_selector.label]
#    "component" = "kube-controller-manager"

[[inputs.dice_health]]
  interval = "5m"
  [inputs.dice_health.service_check]
    timeout = "30s"
  [inputs.dice_health.k8s_filter]
    namespace = "default"
    [[inputs.dice_health.k8s_filter.label_filters]]
      key = "dice/component"
      operator = "neq"
      value = ""

[[inputs.spark]]
  # urls = []
  ## Set response_timeout (default 5 seconds)
  timeout = "10s"
  job_include = true
  stage_include = false

  [inputs.spark.k8s_service_discovery]
    port = 4040
    namespace = "default"
    name_include = ["spark-thrift-server*"]
    protocol = "TCP"

[[inputs.global_kubernetes]] # 共享 kubernetes client, 不主动采集数据
    k8s_url = "$MASTER_VIP_URL"
    k8s_timeout = "${K8S_TIMEOUT:20s}"
    k8s_bearer_token = "${K8S_BEARER_TOKEN:/run/secrets/kubernetes.io/serviceaccount/token}"
    [inputs.global_kubernetes.k8s_client_config]
        tls_ca = "${K8S_TLS_CA:/run/secrets/kubernetes.io/serviceaccount/ca.crt}"
